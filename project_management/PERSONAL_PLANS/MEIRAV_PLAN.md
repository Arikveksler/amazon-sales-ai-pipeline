# ×ª×•×›× ×™×ª ×¢×‘×•×“×” - ××™×¨×‘ (×•×œ×™×“×¦×™×” ×•×™×¦×™×‘×•×ª)

## ×ª×¤×§×™×“ ×›×œ×œ×™
×•×œ×™×“×¦×™×” ×•×™×¦×™×‘×•×ª - ××—×¨××™×ª ×¢×œ ×—×•×–×” ×”× ×ª×•× ×™×, ×”×¢×¨×›×ª ××•×“×œ, ×•×× ×’× ×•× ×™ Fail Gracefully.

## Branch: `feature/meirav`

---

## ×©×‘×•×¢ 1: Dataset Contract

### ××©×™××•×ª
| # | ××©×™××” | ×ª×œ×•×™ ×‘- | ×ª×•×¦×¨ | Status |
|---|--------|---------|------|--------|
| 1 | ×”×’×“×¨×ª dataset_contract.json | - | dataset_contract.json | â¬œ |
| 2 | ×”×’×“×¨×ª constraints | - | constraints in JSON | â¬œ |

### ××‘× ×” ×”×—×•×–×”
```json
{
  "dataset_name": "amazon_sales_clean",
  "version": "1.0.0",
  "created_at": "2024-XX-XX",
  "created_by": "Analyst Crew",
  "description": "Amazon product sales data for price prediction",
  "source": "Kaggle Amazon Sales Dataset",

  "required_columns": [
    "product_id",
    "product_name",
    "category",
    "discounted_price",
    "actual_price",
    "rating"
  ],

  "constraints": {
    "discounted_price": {
      "type": "numeric",
      "min": 0,
      "required": true
    },
    "actual_price": {
      "type": "numeric",
      "min": 0,
      "required": true
    },
    "rating": {
      "type": "numeric",
      "min": 0,
      "max": 5,
      "required": true
    },
    "discount_percentage": {
      "type": "numeric",
      "min": 0,
      "max": 100
    },
    "product_id": {
      "type": "string",
      "unique": true,
      "required": true
    },
    "category": {
      "type": "categorical",
      "required": true
    }
  },

  "schema": {
    "columns": ["..."],
    "dtypes": {"...": "..."},
    "row_count": 1463
  },

  "quality_checks": {
    "no_nulls": true,
    "validated": true
  },

  "min_features": 5
}
```

### ×—×©×•×‘ ×œ×“×¢×ª
- ×”×§×•×‘×¥ `validators.py` (×©×•×¨×” 202) ××¦×¤×” ×œ×©×“×•×ª `required_columns` ×•-`constraints`
- ×—×™×™×‘ ×œ×”×•×¡×™×£ ××•×ª× ×œ×—×•×–×” ×”×§×™×™×!

### ×ª×•×¦×¨×™×
- [ ] `data/contracts/dataset_contract.json` ××¢×•×“×›×Ÿ

---

## ×©×‘×•×¢ 2: ×”×¢×¨×›×ª ××•×“×œ ×•×ª×™×¢×•×“

### ××©×™××•×ª
| # | ××©×™××” | ×ª×œ×•×™ ×‘- | ×ª×•×¦×¨ | Status |
|---|--------|---------|------|--------|
| 1 | Evaluation Report | model (× ×•×•×”) | evaluation_report.md | â¬œ |
| 2 | Model Card | model (× ×•×•×”) | model_card.md | â¬œ |

### ×“×•×— ×”×¢×¨×›×” (evaluation_report.md)
```markdown
# Model Evaluation Report

## 1. Overview
- **Model Type**: [Linear Regression / Random Forest]
- **Target Variable**: discounted_price
- **Training Date**: [×ª××¨×™×š]
- **Dataset Size**: 1,463 samples

## 2. Performance Metrics
| Metric | Linear Regression | Random Forest | Winner |
|--------|-------------------|---------------|--------|
| MAE    | X.XX             | X.XX          | RF/LR  |
| RMSE   | X.XX             | X.XX          | RF/LR  |
| RÂ²     | X.XX             | X.XX          | RF/LR  |
| MAPE   | X.XX%            | X.XX%         | RF/LR  |

## 3. Feature Importance (Top 5)
1. actual_price - XX%
2. category - XX%
3. rating - XX%
4. discount_percentage - XX%
5. rating_count - XX%

## 4. Cross-Validation Results
- 5-Fold CV Mean Score: X.XX
- Standard Deviation: X.XX

## 5. Recommendations
[×”××œ×¦×” ×¢×œ ××™×–×” ××•×“×œ ×œ×‘×—×•×¨ ×•×œ××”]
```

### ×›×¨×˜×™×¡ ××•×“×œ (model_card.md)
**×—×©×•×‘**: ×”×¤×•× ×§×¦×™×” `validate_model_outputs()` ×‘×•×“×§×ª ×©×”×¡×§×©× ×™× ×”×‘××™× ×§×™×™××™×:
- Purpose
- Data
- Metrics
- Limitations
- Ethical

```markdown
# Model Card: Amazon Sales Price Predictor

## Purpose
### Model Details
- **Name**: Amazon Sales Price Predictor
- **Version**: 1.0
- **Type**: Regression
- **Framework**: Scikit-learn

### Intended Use
- **Primary use**: Predict discounted prices for Amazon products
- **Users**: Business analysts, pricing teams
- **Out-of-scope**: Real-time production pricing decisions

## Data
### Training Data
- **Source**: Kaggle Amazon Sales Dataset
- **Size**: ~1,463 records
- **Features**: Product category, actual price, ratings, etc.

### Data Processing
- Removed rows with null values
- Categorical encoding for category field

## Metrics
### Performance Results
| Metric | Value |
|--------|-------|
| MAE    | X.XX  |
| RMSE   | X.XX  |
| RÂ²     | X.XX  |

## Limitations
- Limited to product categories present in training data
- May not generalize to new product types
- Small dataset size (1,463 samples)
- Does not account for seasonal trends

## Ethical Considerations
### Bias Concerns
- Model trained on specific Amazon product categories
- May have bias towards certain price ranges

### Privacy
- No personal user data used in predictions

### Fairness
- Equal treatment across all product categories

### Transparency
- All features and logic fully documented
```

### ×ª×•×¦×¨×™×
- [ ] `outputs/reports/evaluation_report.md`
- [ ] `outputs/reports/model_card.md`

---

## ×©×‘×•×¢ 3: Fail Gracefully

### ××©×™××•×ª
| # | ××©×™××” | ×ª×œ×•×™ ×‘- | ×ª×•×¦×¨ | Status |
|---|--------|---------|------|--------|
| 1 | validate_against_constraints | contract | validators.py | â¬œ |
| 2 | UserFriendlyErrors | - | error_handler.py | â¬œ |
| 3 | _fail_gracefully method | flow (××¨×™×§) | main_flow.py | â¬œ |

### ×¤×•× ×§×¦×™×™×ª ×•×œ×™×“×¦×™×” ××•×œ constraints
```python
# ×œ×”×•×¡×™×£ ×œ-src/flow/validators.py

def validate_against_constraints(df: pd.DataFrame, contract: dict) -> Tuple[bool, str]:
    """×‘×“×™×§×ª DataFrame ××•×œ ××™×œ×•×¦×™ ×”×—×•×–×”."""
    logger.info("ğŸ” Validating data against contract constraints")

    errors = []
    constraints = contract.get('constraints', {})

    if not constraints:
        logger.warning("âš  No constraints defined in contract")
        return True, "No constraints to validate"

    for column, rules in constraints.items():
        if column not in df.columns:
            if rules.get('required', False):
                errors.append(f"×¢××•×“×” ×—×•×‘×” ×—×¡×¨×”: {column}")
            continue

        col_data = df[column]

        # ×‘×“×™×§×ª ×¢×¨×›×™× ××¡×¤×¨×™×™×
        if rules.get('type') == 'numeric':
            try:
                numeric_data = pd.to_numeric(
                    col_data.astype(str).str.replace('[â‚¹,]', '', regex=True),
                    errors='coerce'
                )

                if 'min' in rules:
                    below_min = numeric_data < rules['min']
                    if below_min.any():
                        errors.append(f"{column}: {below_min.sum()} ×¢×¨×›×™× ××ª×—×ª ×œ××™× ×™××•×")

                if 'max' in rules:
                    above_max = numeric_data > rules['max']
                    if above_max.any():
                        errors.append(f"{column}: {above_max.sum()} ×¢×¨×›×™× ××¢×œ ××§×¡×™××•×")
            except Exception as e:
                errors.append(f"{column}: ×©×’×™××” ×‘×”××¨×” - {str(e)}")

        # ×‘×“×™×§×ª ×™×™×—×•×“×™×•×ª
        if rules.get('unique', False):
            duplicates = col_data.duplicated().sum()
            if duplicates > 0:
                errors.append(f"{column}: {duplicates} ×¢×¨×›×™× ×›×¤×•×œ×™×")

        # ×‘×“×™×§×ª ×¢×¨×›×™× ×—×¡×¨×™×
        if rules.get('required', False):
            null_count = col_data.isnull().sum()
            if null_count > 0:
                errors.append(f"{column}: {null_count} ×¢×¨×›×™× ×—×¡×¨×™×")

    if errors:
        return False, "; ".join(errors)

    return True, f"Validated {len(constraints)} constraints"
```

### ×”×•×“×¢×•×ª ×©×’×™××” ×™×“×™×“×•×ª×™×•×ª
```python
# ×œ×”×•×¡×™×£ ×œ-src/utils/error_handler.py

class UserFriendlyErrors:
    """×”×•×“×¢×•×ª ×©×’×™××” ×™×“×™×“×•×ª×™×•×ª ×‘×¢×‘×¨×™×ª."""

    MESSAGES = {
        'file_not_found': "×”×§×•×‘×¥ '{file}' ×œ× × ××¦×. ×× × ×•×“× ×©×”×§×•×‘×¥ ×§×™×™× ×‘-{path}",
        'invalid_data': "×”× ×ª×•× ×™× ×œ× ×ª×§×™× ×™×: {reason}",
        'contract_violation': "×”× ×ª×•× ×™× ×œ× ×¢×•××“×™× ×‘×—×•×–×”: {violations}",
        'model_training_failed': "××™××•×Ÿ ×”××•×“×œ × ×›×©×œ: {reason}",
        'validation_failed': "×”×•×œ×™×“×¦×™×” × ×›×©×œ×” ×‘×©×œ×‘ '{stage}': {details}",
        'crew_failed': "×¦×•×•×ª {crew} × ×›×©×œ ×‘×‘×™×¦×•×¢ ×”××©×™××”: {reason}",
        'missing_columns': "×¢××•×“×•×ª ×—×¡×¨×•×ª ×‘× ×ª×•× ×™×: {columns}",
        'null_values': "× ××¦××• ×¢×¨×›×™× ×—×¡×¨×™× ×‘×¢××•×“×•×ª: {columns}"
    }

    @classmethod
    def get(cls, error_type: str, **kwargs) -> str:
        template = cls.MESSAGES.get(error_type, "×©×’×™××” ×œ× ×™×“×•×¢×”")
        try:
            return template.format(**kwargs)
        except KeyError:
            return template
```

### ××ª×•×“×ª _fail_gracefully
```python
# ×œ×”×•×¡×™×£ ×œ-src/flow/main_flow.py

def _fail_gracefully(self, stage: str, error: Exception, user_message: str) -> dict:
    """×˜×™×¤×•×œ ×‘×›×©×œ×•×Ÿ ×‘×¦×•×¨×” ×‘×¨×•×¨×” ×œ××©×ª××©."""
    logger.error("=" * 50)
    logger.error(f"âŒ Pipeline × ×›×©×œ ×‘×©×œ×‘: {stage}")
    logger.error(f"ğŸ“‹ ×”×•×“×¢×”: {user_message}")
    logger.error(f"ğŸ” ×¤×¨×˜×™×: {str(error)}")
    logger.error("=" * 50)

    self.state["status"] = "failed"
    self.state["error"] = {
        "stage": stage,
        "message": user_message,
        "details": str(error),
        "timestamp": datetime.now().isoformat()
    }
    self._save_state(stage, "failed", {"error": user_message})

    return {
        "status": "failed",
        "stage": stage,
        "message": user_message
    }
```

### ×ª×•×¦×¨×™×
- [ ] `src/flow/validators.py` - validate_against_constraints
- [ ] `src/utils/error_handler.py` - UserFriendlyErrors
- [ ] `src/flow/main_flow.py` - _fail_gracefully (×‘×ª×™××•× ×¢× ××¨×™×§)

---

## ×©×‘×•×¢ 4: QA ×¡×•×¤×™

### ××©×™××•×ª
| # | ××©×™××” | ×ª×œ×•×™ ×‘- | ×ª×•×¦×¨ | Status |
|---|--------|---------|------|--------|
| 1 | QA Checklist | all | ×‘×“×™×§×•×ª ××¢×¨×›×ª | â¬œ |
| 2 | ×‘×“×™×§×•×ª E2E | working system | passing tests | â¬œ |
| 3 | ××™×¡×•×£ Artifacts | all | ×›×œ ×”×§×‘×¦×™× ×‘-Repo | â¬œ |
| 4 | ×“×•×— QA ×¡×•×¤×™ | tests | QA_report.md | â¬œ |

### Checklist QA
```
â–¡ Pipeline
  â–¡ ×”×¨×¦×” ××”×”×ª×—×œ×” ×œ×¡×•×£ ×‘×œ×™ ×©×’×™××•×ª
  â–¡ ×›×œ ×”×©×œ×‘×™× ××ª×•×¢×“×™× ×‘-logs
  â–¡ State × ×©××¨ ×œ-JSON

â–¡ ×§×‘×¦×™ × ×ª×•× ×™×
  â–¡ data/raw/amazon_sales.csv ×§×™×™×
  â–¡ data/processed/clean_data.csv × ×•×¦×¨
  â–¡ data/contracts/dataset_contract.json ×ª×§×™×Ÿ
  â–¡ data/features/features.csv × ×•×¦×¨

â–¡ ×ª×•×¦×¨×™ ××•×“×œ
  â–¡ outputs/models/model.pkl ×§×™×™× ×•×œ× ×¨×™×§
  â–¡ outputs/reports/evaluation_report.md ××œ×
  â–¡ outputs/reports/model_card.md ×¢× ×›×œ ×”×¡×§×©× ×™×

â–¡ ×××©×§ ××©×ª××©
  â–¡ Streamlit ×¨×¥ ×‘×œ×™ ×©×’×™××•×ª
  â–¡ ×’×¨×¤×™× ××•×¦×’×™×
  â–¡ Prediction ×¢×•×‘×“

â–¡ Fail Gracefully
  â–¡ ×”×•×“×¢×” ×‘×¨×•×¨×” ×›×©×—×¡×¨ ×§×•×‘×¥
  â–¡ ×”×•×“×¢×” ×‘×¨×•×¨×” ×›×©× ×ª×•× ×™× ×œ× ×ª×§×™× ×™×
  â–¡ State × ×©××¨ ×’× ×‘×›×©×œ×•×Ÿ

â–¡ Git
  â–¡ README ××¢×•×“×›×Ÿ
  â–¡ ××™×Ÿ ×§×‘×¦×™× ×¨×’×™×©×™×
  â–¡ requirements.txt ××œ×
```

### ×¤×§×•×“×•×ª ×‘×“×™×§×”
```bash
# ×‘×“×™×§×ª Pipeline
python -c "from src.flow.main_flow import AmazonSalesPipeline; p = AmazonSalesPipeline(); p.run()"

# ×‘×“×™×§×ª Fail Gracefully
python -c "
from src.flow.main_flow import AmazonSalesPipeline
p = AmazonSalesPipeline()
p.raw_data_path = p.project_root / 'nonexistent.csv'
result = p.run()
print('OK!' if result.get('status') == 'failed' else 'PROBLEM!')
"

# ×‘×“×™×§×•×ª pytest
pytest tests/ -v

# Streamlit
streamlit run app/streamlit_app.py
```

### ×ª×•×¦×¨×™×
- [ ] QA checklist ××œ×
- [ ] ×›×œ ×”×‘×“×™×§×•×ª ×¢×•×‘×¨×•×ª
- [ ] ×›×œ ×”-Artifacts ×‘-Repo

---

## ×§×‘×¦×™× ×‘××—×¨×™×•×ª×™

| ×§×•×‘×¥ | ×ª×™××•×¨ |
|------|-------|
| `data/contracts/dataset_contract.json` | ×—×•×–×” × ×ª×•× ×™× |
| `outputs/reports/evaluation_report.md` | ×“×•×— ×”×¢×¨×›×” |
| `outputs/reports/model_card.md` | ×›×¨×˜×™×¡ ××•×“×œ |
| `src/flow/validators.py` | ×¤×•× ×§×¦×™×•×ª ×•×œ×™×“×¦×™×” |
| `src/utils/error_handler.py` | ×˜×™×¤×•×œ ×‘×©×’×™××•×ª |

---

## × ×§×•×“×•×ª ×××©×§

### ××§×‘×œ ×:
- **× ×•×•×”**: model.pkl ×œ××˜×¨×™×§×•×ª
- **××¨×™×§**: main_flow.py ×œ××™× ×˜×’×¨×¦×™×”

### × ×•×ª×Ÿ ×œ:
- **×›×•×œ×**: dataset_contract.json
- **××¨×™×§**: error handling code
- **××—×™××‘**: model_card ×œ××ª×™×§×”

---

## ×ª×œ×•×™×•×ª ×‘×—×‘×¨×™ ×¦×•×•×ª

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   × ×•×•×” (4)      â”‚     â”‚   ××¨×™×§ (1)      â”‚
â”‚   ××××Ÿ ××•×“×œ     â”‚     â”‚   main_flow.py  â”‚
â”‚   model.pkl     â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ××™×¨×‘ (5)                   â”‚
â”‚  ×©×‘×•×¢ 1: contract (×œ× ×ª×œ×•×™!)           â”‚
â”‚  ×©×‘×•×¢ 2: eval + card (×ª×œ×•×™ ×‘× ×•×•×”!)     â”‚
â”‚  ×©×‘×•×¢ 3: Fail gracefully (×ª×œ×•×™ ×‘××¨×™×§!) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ×”××œ×¦×•×ª ×œ×ª×™××•×
1. **×©×‘×•×¢ 1**: ×”×ª×—×™×œ×™ ××™×“! ×œ× ×ª×œ×•×™ ×‘××£ ××—×“
2. **×©×‘×•×¢ 2**: ×ª×××™ ×¢× × ×•×•×” - ×¦×¨×™×›×” ××ª ×”××•×“×œ ×©×œ×•
3. **×©×‘×•×¢ 3**: ×ª×××™ ×¢× ××¨×™×§ - ×¦×¨×™×›×” ×œ×©×œ×‘ ×§×•×“ ×œ-Flow
