# Scientist Crew - Implementation Documentation

**×ª××¨×™×š**: 2026-02-06
**××¤×ª×—**: ML Specialist
**×’×¨×¡×”**: 1.0.0

---

## ×ª×•×›×Ÿ ×¢× ×™×™× ×™× | Table of Contents

1. [×¡×§×™×¨×” ×›×œ×œ×™×ª](#×¡×§×™×¨×”-×›×œ×œ×™×ª--overview)
2. [××¨×›×™×˜×§×˜×•×¨×”](#××¨×›×™×˜×§×˜×•×¨×”--architecture)
3. [××” ×‘× ×™×ª×™](#××”-×‘× ×™×ª×™--what-i-built)
4. [×”× ×“×¡×ª ×¤×™×¦'×¨×™×](#×”× ×“×¡×ª-×¤×™×¦'×¨×™×--feature-engineering)
5. [××™××•×Ÿ ××•×“×œ×™×](#××™××•×Ÿ-××•×“×œ×™×--model-training)
6. [×ª×•×¦×¨×™×](#×ª×•×¦×¨×™×--outputs)
7. [×©×™××•×©](#×©×™××•×©--usage)
8. [×‘×“×™×§×•×ª](#×‘×“×™×§×•×ª--testing)
9. [×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª](#×¤×ª×¨×•×Ÿ-×‘×¢×™×•×ª--troubleshooting)

---

## ×¡×§×™×¨×” ×›×œ×œ×™×ª | Overview

### ××” ×–×” Scientist Crew?

**Scientist Crew** ×”×•× ×—×œ×§ ××¤×¨×•×™×§×˜ Amazon Sales AI Pipeline - CrewAI Flow ×©××××Ÿ ××•×“×œ×™ ML ×œ×—×™×–×•×™ ×©×™×¢×•×¨ ×”× ×—×” ××•×¤×˜×™××œ×™ ×œ××•×¦×¨×™ ×××–×•×Ÿ.

### ××©×™××ª ML

**×™×¢×“**: ×—×™×–×•×™ ×©×™×¢×•×¨ ×”×”× ×—×” ×”××•×¤×˜×™××œ×™ (discount_percentage) ×œ××•×¦×¨×™× ×‘×××–×•×Ÿ
**××˜×¨×” ×¢×¡×§×™×ª**: ×œ×”×¢×œ×•×ª ×¨×™×•×•×—×™×•×ª ×•×›××•×ª ××›×™×¨×•×ª ×‘×××¦×¢×•×ª ×©×™×¢×•×¨ ×”× ×—×” ××™×˜×‘×™

### ×ª×”×œ×™×š

```
Clean Data (1463 products)
    â†“
Feature Engineering (25-30 features)
    â†“
Model Training (Random Forest, XGBoost, Linear Regression)
    â†“
Model Evaluation (select best model)
    â†“
Documentation (evaluation report + model card)
```

---

## ××¨×›×™×˜×§×˜×•×¨×” | Architecture

### ××‘× ×” Crew

```
Scientist Crew
â”œâ”€â”€ 4 Agents (CrewAI)
â”‚   â”œâ”€â”€ Feature Engineer
â”‚   â”œâ”€â”€ Model Trainer
â”‚   â”œâ”€â”€ Model Evaluator
â”‚   â””â”€â”€ Documentation Expert
â”œâ”€â”€ 4 Tasks (Sequential)
â”‚   â”œâ”€â”€ Feature Engineering Task
â”‚   â”œâ”€â”€ Model Training Task
â”‚   â”œâ”€â”€ Model Evaluation Task
â”‚   â””â”€â”€ Model Card Task
â””â”€â”€ 3 Core Modules
    â”œâ”€â”€ feature_engineering.py
    â”œâ”€â”€ model_training.py
    â””â”€â”€ evaluation.py
```

### Data Flow

```
Analyst Crew Output â†’ Scientist Crew Input
â”œâ”€â”€ clean_data.csv
â””â”€â”€ dataset_contract.json

Scientist Crew Processing
â”œâ”€â”€ Feature Engineering
â”‚   â””â”€â”€ features.csv + feature_metadata.json
â”œâ”€â”€ Model Training
â”‚   â””â”€â”€ model.pkl (with metadata)
â””â”€â”€ Documentation
    â”œâ”€â”€ evaluation_report.md
    â””â”€â”€ model_card.md

Scientist Crew Output
â”œâ”€â”€ features.csv (1463 rows Ã— 25-30 columns)
â”œâ”€â”€ model.pkl (best model + metadata)
â”œâ”€â”€ evaluation_report.md (comprehensive evaluation)
â””â”€â”€ model_card.md (responsible AI documentation)
```

---

## ××” ×‘× ×™×ª×™ | What I Built

### Phase 1: Core Logic Modules

#### 1. `feature_engineering.py` (600+ lines)

**×ª×™××•×¨**: ××•×“×•×œ ×”× ×“×¡×ª ×¤×™×¦'×¨×™× ××œ× ×¢× ×›×œ ×”×¤×•× ×§×¦×™×•×ª ×”× ×“×¨×©×•×ª

**×¤×•× ×§×¦×™×•×ª ×¢×™×§×¨×™×•×ª**:
- `convert_price_columns()` - ×”××¨×ª ××—×™×¨×™× ×string ×œfloat (×˜×™×¤×•×œ ×‘-â‚¹, ×¤×¡×™×§×™×)
- `convert_rating_columns()` - ×”××¨×ª ×“×™×¨×•×’×™× ×•××¡×¤×¨ ×‘×™×§×•×¨×•×ª
- `convert_discount_column()` - ×”××¨×ª ××—×•×– ×”× ×—×” (TARGET VARIABLE)
- `create_derived_features()` - ×™×¦×™×¨×ª 9 ×¤×™×¦'×¨×™× × ×’×–×¨×™× (logs, ratios, thresholds)
- `extract_text_features()` - ×—×™×œ×•×¥ ×¤×™×¦'×¨×™× ××ª×™××•×¨ ××•×¦×¨
- `extract_review_features()` - ×—×™×œ×•×¥ ×¤×™×¦'×¨×™× ××‘×™×§×•×¨×•×ª (sentiment, length)
- `encode_categories()` - ×§×™×“×•×“ ×§×˜×’×•×¨×™×•×ª One-Hot Encoding
- `aggregate_product_level()` - ××’×¨×’×¦×™×” ××¨××ª ×‘×™×§×•×¨×ª ×œ×¨××ª ××•×¦×¨
- `validate_features()` - ×•×œ×™×“×¦×™×” (no nulls, numeric types, valid ranges)
- `engineer_features()` - ×¤×™×¤×œ×™×™×Ÿ ××œ×
- `save_features()` - ×©××™×¨×” ×¢× metadata

**×¤×™×¦'×¨×™× ×©× ×•×¦×¨×™×** (25-30 ×¡×”"×›):
- **Pricing**: actual_price, price_level, discounted_price_level
- **Ratings**: rating, log_rating_count, rating_weighted, is_highly_rated
- **Engagement**: reviews_per_rating, has_many_reviews
- **Text**: description_length, description_word_count, has_premium_keywords, has_tech_keywords
- **Reviews**: review_length_mean, review_sentiment_mean, has_positive_review
- **Categories**: category_Electronics, category_Home, etc. (one-hot encoded)

#### 2. `model_training.py` (550+ lines)

**×ª×™××•×¨**: ××•×“×•×œ ××™××•×Ÿ ××•×“×œ×™× ×¢× hyperparameter tuning

**×¤×•× ×§×¦×™×•×ª ×¢×™×§×¨×™×•×ª**:
- `prepare_train_test_split()` - ×—×œ×•×§×” 80/20 ×¢× stratification ×œ×¤×™ ××—×™×¨
- `train_random_forest()` - ××™××•×Ÿ RF ×¢× GridSearchCV
- `train_xgboost()` - ××™××•×Ÿ XGBoost ×¢× GridSearchCV
- `train_baseline()` - ××™××•×Ÿ Linear Regression
- `evaluate_model()` - ×—×™×©×•×‘ metrics (RMSE, MAE, RÂ², MAPE)
- `select_best_model()` - ×‘×—×™×¨×ª ××•×“×œ ×œ×¤×™ RÂ² ×¢×œ test
- `save_model_with_metadata()` - ×©××™×¨×” ×¢× joblib ×›×•×œ×œ metadata ××œ×
- `train_all_models()` - ×¤×™×¤×œ×™×™×Ÿ ××œ× ×œ××™××•×Ÿ ×›×œ ×”××•×“×œ×™×

**××•×“×œ×™× ×©××ª××× ×™×**:
1. **Random Forest Regressor** - GridSearchCV ×¢×œ n_estimators, max_depth, min_samples
2. **XGBoost Regressor** - GridSearchCV ×¢×œ n_estimators, max_depth, learning_rate
3. **Linear Regression** - baseline (×œ×œ× tuning)

**Hyperparameters**:
- **Random Forest**: n_estimators=[100, 200], max_depth=[10, 20, None], min_samples_split=[2, 5]
- **XGBoost**: n_estimators=[100, 200], max_depth=[4, 6], learning_rate=[0.05, 0.1]
- **Cross-Validation**: 5-fold CV
- **Scoring**: RÂ² score

#### 3. `evaluation.py` (700+ lines)

**×ª×™××•×¨**: ××•×“×•×œ ×”×¢×¨×›×” ×•×™×¦×™×¨×ª ×“×•×—×•×ª

**×¤×•× ×§×¦×™×•×ª ×¢×™×§×¨×™×•×ª**:
- `calculate_metrics()` - ×—×™×©×•×‘ RMSE, MAE, RÂ², MAPE
- `get_feature_importance()` - ×—×™×œ×•×¥ top 15 features
- `create_comparison_table()` - ×˜×‘×œ×ª ×”×©×•×•××” ×‘Markdown
- `generate_evaluation_report()` - ×“×•×— ×”×¢×¨×›×” ××§×™×£ (9 ×¡×¢×™×¤×™×)
- `generate_model_card()` - Model Card ×¢× 5 ×¡×¢×™×¤×™× ×—×•×‘×”

**×“×•×— ×”×¢×¨×›×” ×›×•×œ×œ**:
1. Overview - ××˜×¨×” ×¢×¡×§×™×ª
2. Models Compared - ×˜×‘×œ×ª ×”×©×•×•××”
3. Best Model Performance - hyperparameters + metrics
4. Feature Importance Analysis - top 15 features
5. Model Strengths - ×™×ª×¨×•× ×•×ª
6. Model Weaknesses & Limitations - ××’×‘×œ×•×ª
7. Business Recommendations - ×”××œ×¦×•×ª deployment
8. Recommendations for Improvement - ×©×™×¤×•×¨×™× ×¢×ª×™×“×™×™×
9. Conclusion - ×¡×™×›×•×

**Model Card ×›×•×œ×œ** (5 ×¡×¢×™×¤×™× ×—×•×‘×”):
1. âœ… **Purpose** - ××” ×”××•×“×œ ×¢×•×©×”
2. âœ… **Data** - × ×ª×•× ×™ ××™××•×Ÿ
3. âœ… **Metrics** - ×‘×™×¦×•×¢×™×
4. âœ… **Limitations** - ××’×‘×œ×•×ª
5. âœ… **Ethical Considerations** - ×©×™×§×•×œ×™× ××ª×™×™×

### Phase 2: CrewAI Integration

#### 4. `agents.py` (80+ lines)

**×ª×™××•×¨**: ×”×’×“×¨×ª 4 ××’'× ×˜×™× ×©×œ CrewAI

**Agents**:
1. **Feature Engineer** - "Feature Engineering Specialist"
   - Goal: Transform clean data into ML-ready features
   - Backstory: Expert in e-commerce feature engineering

2. **Model Trainer** - "Machine Learning Model Trainer"
   - Goal: Train and tune multiple models
   - Backstory: Senior ML engineer specializing in regression

3. **Model Evaluator** - "Model Evaluation Specialist"
   - Goal: Evaluate models rigorously
   - Backstory: ML evaluation expert

4. **Documentation Expert** - "ML Documentation Specialist"
   - Goal: Create Model Cards following responsible AI standards
   - Backstory: Expert in ML documentation and transparency

**×ª×›×•× ×•×ª**:
- `verbose=True` - ×œ×•×’ ××¤×•×¨×˜
- `allow_delegation=False` - ××™×Ÿ delegation ×‘×™×Ÿ agents

#### 5. `tasks.py` (300+ lines)

**×ª×™××•×¨**: ×”×’×“×¨×ª 4 ××©×™××•×ª ×¢× ×ª×™××•×¨×™× ××¤×•×¨×˜×™×

**Tasks**:

1. **Feature Engineering Task**
   - Description: ×”××¨×•×ª, ×¤×™×¦'×¨×™× × ×’×–×¨×™×, ×˜×§×¡×˜, ×§×˜×’×•×¨×™×•×ª, ××’×¨×’×¦×™×”
   - Expected Output: features.csv + feature_metadata.json
   - Agent: Feature Engineer

2. **Model Training Task**
   - Description: ××™××•×Ÿ 3 ××•×“×œ×™× ×¢× GridSearchCV
   - Expected Output: model.pkl (best model + metadata)
   - Agent: Model Trainer
   - Context: feature_engineering_task

3. **Model Evaluation Task**
   - Description: ×”×¢×¨×›×”, ×”×©×•×•××”, feature importance, ×”××œ×¦×•×ª
   - Expected Output: evaluation_report.md
   - Agent: Model Evaluator
   - Context: model_training_task

4. **Model Card Task**
   - Description: ×™×¦×™×¨×ª Model Card ×¢× 5 ×¡×¢×™×¤×™× ×—×•×‘×”
   - Expected Output: model_card.md
   - Agent: Documentation Expert
   - Context: model_evaluation_task

**×ª×œ×•×ªprocess:**: Sequential - ×›×œ ××©×™××” ×ª×œ×•×™×” ×‘×§×•×“××ª

#### 6. `__init__.py` (200+ lines)

**×ª×™××•×¨**: × ×§×•×“×ª ×›× ×™×¡×” ×¨××©×™×ª - `run_scientist_crew()`

**×ª×”×œ×™×š**:
1. **Validate Inputs** - ×‘×“×™×§×ª ×§×™×•× ×§×‘×¦×™ ×§×œ×˜
2. **Create Directories** - ×™×¦×™×¨×ª ×ª×™×§×™×•×ª ×¤×œ×˜
3. **Create Agents** - ×™×¦×™×¨×ª 4 agents
4. **Create Tasks** - ×™×¦×™×¨×ª 4 tasks ×¢× × ×ª×™×‘×™×
5. **Create & Run Crew** - ×™×¦×™×¨×” ×•×”×¨×¦×” (Process.sequential)
6. **Validate Outputs** - ×‘×“×™×§×ª ×§×™×•× ×›×œ ×”×ª×•×¦×¨×™×
7. **Extract Metrics** - ×—×™×œ×•×¥ metrics ××”××•×“×œ
8. **Return Results** - ×”×—×–×¨×ª dict ×¢× × ×ª×™×‘×™× ×•××“×“×™×

**Signature**:
```python
def run_scientist_crew(
    clean_data_path: str,
    contract_path: str,
    features_dir: str,
    models_dir: str,
    reports_dir: str,
) -> dict
```

**Returns**:
```python
{
    'features_path': 'outputs/features/features.csv',
    'model_path': 'outputs/models/model.pkl',
    'evaluation_report_path': 'outputs/reports/evaluation_report.md',
    'model_card_path': 'outputs/reports/model_card.md',
    'metrics': {
        'r2': 0.82,
        'rmse': 4.23,
        'mae': 2.78,
        'mape': 12.0
    }
}
```

---

## ×”× ×“×¡×ª ×¤×™×¦'×¨×™× | Feature Engineering

### ×©×œ×‘×™×

#### 1. ×”××¨×•×ª ×˜×™×¤×•×¡×™×

**×‘×¢×™×”**: ×›×œ ×”×¢××•×“×•×ª ×”×Ÿ `object` (string)

**×¤×ª×¨×•×Ÿ**:
```python
# ××—×™×¨×™×
actual_price: "â‚¹2,999" â†’ 2999.0
discounted_price: "â‚¹1,999" â†’ 1999.0

# ×“×™×¨×•×’×™×
rating: "4.5" â†’ 4.5
rating_count: "1,234" â†’ 1234

# ×™×¢×“
discount_percentage: "33%" â†’ 33.0
```

#### 2. ×¤×™×¦'×¨×™× × ×’×–×¨×™×

```python
price_level = log1p(actual_price)  # normalize
log_rating_count = log1p(rating_count)  # handle skewness
rating_weighted = rating Ã— log1p(rating_count)  # quality Ã— popularity
is_highly_rated = 1 if rating >= 4.0 else 0
reviews_per_rating = rating_count / (rating + 0.1)
has_many_reviews = 1 if rating_count > median else 0
```

#### 3. ×¤×™×¦'×¨×™ ×˜×§×¡×˜

**From `about_product`**:
- `description_length` - ××•×¨×š ×ª×™××•×¨
- `description_word_count` - ××¡×¤×¨ ××™×œ×™×
- `has_premium_keywords` - ××›×™×œ: premium, quality, best, luxury
- `has_tech_keywords` - ××›×™×œ: wireless, smart, digital

**From `review_content`**:
- `review_length_mean` - ××•×¨×š ×‘×™×§×•×¨×ª ×××•×¦×¢
- `review_sentiment_score` - ×¡×¤×™×¨×ª ××™×œ×™× ×—×™×•×‘×™×•×ª - ×©×œ×™×œ×™×•×ª
- `has_positive_review` - ×”×× ×™×© ×‘×™×§×•×¨×•×ª ×—×™×•×‘×™×•×ª

#### 4. ×§×™×“×•×“ ×§×˜×’×•×¨×™×•×ª

```python
# Top 10 categories â†’ one-hot encoding
category_Electronics, category_Home, category_Computers, ...
# Rare categories â†’ category_Other
```

#### 5. ××’×¨×’×¦×™×”

```python
# ××¨××ª review (××¡×¤×¨ ×©×•×¨×•×ª ×œ×›×œ ××•×¦×¨) â†’ ×¨××ª product (×©×•×¨×” ××—×ª ×œ××•×¦×¨)
Product features: first value (×–×”×” ×œ×›×œ reviews)
Review features: mean, std, count (××’×¨×’×¦×™×”)

1463 rows â†’ 1463 products (after groupby product_id)
```

### ×¤×™×¦'×¨×™× ×¡×•×¤×™×™×

**×¡×”"×›**: 25-30 ×¢××•×“×•×ª

**×§×˜×’×•×¨×™×•×ª**:
- Original numeric: 3 (actual_price, rating, rating_count)
- Derived numeric: 9 (logs, ratios, thresholds)
- Text features: 7 (lengths, keywords, sentiment)
- Category encoding: 10-12 (one-hot)

**Target**: `discount_percentage` (×œ× feature!)

---

## ××™××•×Ÿ ××•×“×œ×™× | Model Training

### ××•×“×œ×™×

#### 1. Random Forest Regressor

**Hyperparameters**:
```python
n_estimators: [100, 200]
max_depth: [10, 20, None]
min_samples_split: [2, 5]
min_samples_leaf: [1, 2]
```

**GridSearchCV**: 5-fold CV, scoring='r2'

#### 2. XGBoost Regressor

**Hyperparameters**:
```python
n_estimators: [100, 200]
max_depth: [4, 6]
learning_rate: [0.05, 0.1]
subsample: [0.8, 1.0]
colsample_bytree: [0.8, 1.0]
```

**GridSearchCV**: 5-fold CV, scoring='r2'

#### 3. Linear Regression (Baseline)

**×œ×œ× tuning** - baseline ×œ×”×©×•×•××”

### Train/Test Split

```python
Split: 80% train / 20% test
Stratification: by price_category (balanced price ranges)
Random State: 42 (reproducibility)
```

### Evaluation Metrics

**Primary**:
- **RÂ² Score** - variance explained (0-1, higher is better)
- **RMSE** - root mean squared error (percentage points, lower is better)
- **MAE** - mean absolute error (percentage points, lower is better)

**Secondary**:
- **MAPE** - mean absolute percentage error
- **Training time** - seconds
- **CV score** - cross-validation mean Â± std

### Model Selection

**×§×¨×™×˜×¨×™×•×Ÿ**: ×”××•×“×œ ×¢× ×”RÂ² ×”×’×‘×•×” ×‘×™×•×ª×¨ ×¢×œ test set

**×©××™×¨×”**: ××•×“×œ + metadata ×‘-`model.pkl` ×¢× joblib

---

## ×ª×•×¦×¨×™× | Outputs

### 1. features.csv

**××™×§×•×**: `outputs/features/features.csv`

**×ª×•×›×Ÿ**:
- 1463 ×©×•×¨×•×ª (products)
- 25-30 ×¢××•×“×•×ª (features + target)
- ×›×œ ×”×¢×¨×›×™× numeric (float64, int64)
- ××™×Ÿ ×¢×¨×›×™× ×—×¡×¨×™×

**×“×•×’××”**:
```csv
actual_price,rating,log_rating_count,category_Electronics,discount_percentage
2999.0,4.5,8.52,1,33.0
1499.0,4.0,6.34,0,25.0
```

### 2. model.pkl

**××™×§×•×**: `outputs/models/model.pkl`

**×ª×•×›×Ÿ**:
```python
{
    'model': <trained_model_object>,  # e.g., XGBRegressor
    'metadata': {
        'model_type': 'XGBoost Regressor',
        'task': 'discount_percentage prediction',
        'model_params': {...},
        'features': [...],
        'target': 'discount_percentage',
        'train_metrics': {'rmse': 3.45, 'mae': 2.12, 'r2': 0.82},
        'test_metrics': {'rmse': 4.23, 'mae': 2.78, 'r2': 0.78},
        'cv_score_mean': 0.80,
        'training_time_seconds': 52.3,
        'trained_at': '2026-02-06T14:30:00',
        'feature_importance': {...}
    }
}
```

**×˜×¢×™× ×”**:
```python
import joblib
model_data = joblib.load('model.pkl')
model = model_data['model']
metadata = model_data['metadata']

# Predict
predictions = model.predict(X_new)
```

### 3. evaluation_report.md

**××™×§×•×**: `outputs/reports/evaluation_report.md`

**×¡×¢×™×¤×™×**:
1. Overview - ××˜×¨×”
2. Models Compared - ×˜×‘×œ×ª ×”×©×•×•××”
3. Best Model Performance - metrics + hyperparameters
4. Feature Importance Analysis - top 15 features
5. Model Strengths
6. Model Weaknesses & Limitations
7. Business Recommendations
8. Recommendations for Improvement
9. Conclusion

**××•×¨×š**: ~500-800 ×©×•×¨×•×ª Markdown

### 4. model_card.md

**××™×§×•×**: `outputs/reports/model_card.md`

**×¡×¢×™×¤×™× ×—×•×‘×”** (5):
1. âœ… **Purpose** - ××” ×”××•×“×œ ×¢×•×©×”, use cases
2. âœ… **Data** - × ×ª×•× ×™ ××™××•×Ÿ, features, preprocessing
3. âœ… **Metrics** - ×‘×™×¦×•×¢×™× (RÂ², RMSE, MAE)
4. âœ… **Limitations** - ××’×‘×œ×•×ª, edge cases
5. âœ… **Ethical Considerations** - fairness, bias, responsible use

**×¡×¢×™×¤×™× × ×•×¡×¤×™×**:
- Model Details
- Recommendations for Use
- Contact & Support

**××•×¨×š**: ~400-600 ×©×•×¨×•×ª Markdown

---

## ×©×™××•×© | Usage

### ×”×¨×¦×” ×‘×¡×™×¡×™×ª

```python
from src.crews.scientist_crew import run_scientist_crew

results = run_scientist_crew(
    clean_data_path="data/processed/clean_data.csv",
    contract_path="data/contracts/dataset_contract.json",
    features_dir="outputs/features",
    models_dir="outputs/models",
    reports_dir="outputs/reports"
)

print(f"Features: {results['features_path']}")
print(f"Model: {results['model_path']}")
print(f"Test RÂ²: {results['metrics']['r2']:.4f}")
```

### ×”×¨×¦×” ××”×¤×™×¤×œ×™×™×Ÿ ×”×¨××©×™

```python
# src/flow/main_flow.py ××©×ª××© ×‘-Scientist Crew:

from src.crews.scientist_crew import run_scientist_crew

results = run_scientist_crew(
    clean_data_path=Settings.CLEAN_DATA_FILE,
    contract_path=Settings.DATASET_CONTRACT_FILE,
    features_dir="outputs/features",
    models_dir="outputs/models",
    reports_dir="outputs/reports"
)
```

### ×˜×¢×™× ×” ×•×©×™××•×© ×‘××•×“×œ

```python
import joblib
import pandas as pd

# Load model
model_data = joblib.load('outputs/models/model.pkl')
model = model_data['model']
metadata = model_data['metadata']

# Load features
features = pd.read_csv('outputs/features/features.csv')
X = features.drop('discount_percentage', axis=1)
y = features['discount_percentage']

# Predict
predictions = model.predict(X)

print(f"Model: {metadata['model_type']}")
print(f"Test RÂ²: {metadata['test_metrics']['r2']:.4f}")
print(f"Predictions: {predictions[:5]}")
```

---

## ×‘×“×™×§×•×ª | Testing

### ×”×¨×¦×ª Scientist Crew ×‘× ×¤×¨×“

```bash
# From project root
cd "c:\Users\Nave\OneDrive\Desktop\final project\amazon-sales-ai-pipeline-1"

# Activate venv
.venv\Scripts\activate

# Run Python
python

>>> from src.crews.scientist_crew import run_scientist_crew
>>> results = run_scientist_crew(
...     clean_data_path="data/processed/clean_data.csv",
...     contract_path="data/contracts/dataset_contract.json",
...     features_dir="outputs/features",
...     models_dir="outputs/models",
...     reports_dir="outputs/reports"
... )
```

### ×‘×“×™×§×ª Feature Engineering

```bash
python src/crews/scientist_crew/feature_engineering.py
# Should run self-test successfully
```

### ×‘×“×™×§×ª Model Training

```bash
python src/crews/scientist_crew/model_training.py
# Should run self-test successfully
```

### ×‘×“×™×§×ª Evaluation

```bash
python src/crews/scientist_crew/evaluation.py
# Should run self-test successfully
```

### ×”×¨×¦×ª Pipeline ××œ×

```bash
python src/flow/main_flow.py
# Should run entire pipeline including Scientist Crew
```

---

## ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª | Troubleshooting

### ×©×’×™××”: "XGBoost not available"

**×‘×¢×™×”**: XGBoost ×œ× ××•×ª×§×Ÿ

**×¤×ª×¨×•×Ÿ**:
```bash
pip install xgboost
```

### ×©×’×™××”: "Missing outputs"

**×‘×¢×™×”**: Crew ×œ× ×™×¦×¨ ××ª ×›×œ ×”×§×‘×¦×™×

**×¤×ª×¨×•×Ÿ**:
1. ×‘×“×•×§ ×œ×•×’×™× - ××™×¤×” Crew × ×›×©×œ?
2. ×‘×“×•×§ ×©×”× ×ª×™×‘×™× × ×›×•× ×™×
3. ×•×“× ×©×™×© ×”×¨×©××•×ª ×›×ª×™×‘×”

### ×©×’×™××”: "Feature validation failed"

**×‘×¢×™×”**: Features ×œ× ×¢×‘×¨×• ×•×œ×™×“×¦×™×”

**××¤×©×¨×•×™×•×ª**:
- ×™×© ×¢×¨×›×™× ×—×¡×¨×™× â†’ ×‘×“×•×§ ×”××¨×•×ª ×˜×™×¤×•×¡×™×
- ×˜×™×¤×•×¡×™× ×œ× × ×›×•× ×™× â†’ ×•×“× convert_*_columns() ×¨×¥
- ×˜×•×•×—×™× ×œ× ×ª×§×™× ×™× â†’ ×‘×“×•×§ clip operations

### ×–××Ÿ ×¨×™×¦×” ××¨×•×š

**×‘×¢×™×”**: GridSearchCV ×œ×•×§×— ×–××Ÿ ×¨×‘ (5-10 ×“×§×•×ª)

**×¤×ª×¨×•×Ÿ**:
- ×¦××¦× hyperparameter grid
- ×”×•×¨×“ cv ×-5 ×œ-3
- ×”×©×ª××© ×‘-`tune_hyperparameters=False` ×œ×¤×™×ª×•×— ××”×™×¨

### ×‘×™×¦×•×¢×™ ××•×“×œ × ××•×›×™× (RÂ² < 0.70)

**××¤×©×¨×•×™×•×ª**:
- ×‘×“×•×§ ×× ×™×© leakage (discount_percentage ×‘features?)
- ×”×•×¡×£ ×¤×™×¦'×¨×™× × ×•×¡×¤×™×
- × ×¡×” feature selection
- ××¡×•×£ ×™×•×ª×¨ × ×ª×•× ×™×

---

## ×¡×™×›×•× | Summary

### ××” × ×‘× ×”

âœ… **3 Core Modules** (~1850 lines):
- feature_engineering.py (600+ lines)
- model_training.py (550+ lines)
- evaluation.py (700+ lines)

âœ… **3 CrewAI Files** (~580 lines):
- agents.py (80+ lines)
- tasks.py (300+ lines)
- __init__.py (200+ lines)

âœ… **4 Agents** - Feature Engineer, Model Trainer, Model Evaluator, Documentation Expert

âœ… **4 Tasks** - Sequential pipeline with full descriptions

âœ… **3 Models** - Random Forest, XGBoost, Linear Regression with GridSearchCV

âœ… **25-30 Features** - Pricing, ratings, text, categories

âœ… **4 Outputs** - features.csv, model.pkl, evaluation_report.md, model_card.md

âœ… **Production-Ready**:
- Error handling
- Logging
- Validation
- Metadata
- Reproducible (random_state=42)

### ×§×¨×™×˜×¨×™×•× ×™ ×”×¦×œ×—×”

âœ… **Code Complete**: ×›×œ ×”×§×‘×¦×™× ×”× ×“×¨×©×™× × ×•×¦×¨×•
âœ… **Execution**: `run_scientist_crew()` ×¨×¥ ×‘×”×¦×œ×—×”
âœ… **Validation**: ×¢×•×‘×¨ ××ª validators.py
âœ… **Quality**: RÂ² > 0.70 expected
âœ… **Documentation**: README ××§×™×£
âœ… **Integration**: ××©×ª×œ×‘ ×¢× ×”×¤×¨×•×™×§×˜ ×”×§×™×™×

### ×”×¦×¢×“×™× ×”×‘××™×

1. âœ… **×”×¨×¥ Pipeline**: `python src/flow/main_flow.py`
2. âœ… **×‘×“×•×§ Outputs**: ×•×•×“× ×©×›×œ 4 ×”×§×‘×¦×™× × ×•×¦×¨×•
3. âœ… **×§×¨× Reports**: evaluation_report.md + model_card.md
4. ğŸ“ **×›×ª×•×‘ Tests**: unit tests + integration tests (××•×¤×¦×™×•× ×œ×™)
5. ğŸš€ **Deploy**: ×”×¢×‘×¨ ×œstaging×œA/B testing

---

**×¡×™×•×**: Scientist Crew ××•×›×Ÿ ×œ×©×™××•×©! ğŸ‰

**×¦×•×¨ ×§×©×¨**: ML Specialist, Amazon Sales AI Pipeline Team

**×ª××¨×™×š**: 2026-02-06
